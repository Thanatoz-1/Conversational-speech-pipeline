# Conversational-speech-pipeline

Call center recordings contains conversations turns. This means that performing speech processing and analysis pipeline for such data would require separation of client's voice and the call center agent's voice from the recording. The individual voices in the recordings could then be processed to perform various operations on the same. In this repository, we introduce one such pipeline along with proper references and also build api around the same using various techniques based on the kind of data. 

For simplistic pipelines, we came to know that the call recordings are stored in separate channels in [this video](https://www.youtube.com/watch?t=469&v=pGkqwRPzx9U&feature=youtu.be).

Few other blog references are here:
1. https://ai.googleblog.com/2017/11/understanding-medical-conversations.html
2. https://medium.com/saarthi-ai/who-spoke-when-build-your-own-speaker-diarization-module-from-scratch-e7d725ee279
3. 

### References:
#### Datasets available:
1. [RadioTalk: a large-scale corpus of talk radio transcripts](https://github.com/social-machines/RadioTalk)
2. [AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies](https://research.google.com/ava)
3. [AVA-ActiveSpeaker: An Audio-Visual Dataset for Active Speaker Detection](https://research.google.com/ava/download.html#ava_active_speaker_download)

#### Researches available:

#### Applications available:
[Complete implementation of Speaker diarization](https://github.com/WiraDKP/pytorch_speaker_embedding_for_diarization)
[UIS RNN](https://github.com/google/uis-rnn)


For a complete speaker diarization contents and links and guides, you can refer to [this following link](https://github.com/wq2012/awesome-diarization).
